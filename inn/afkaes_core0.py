import arxiv
import json
import datetime
import os
import re
import sys
import glob

# ==========================================
# 1. å“è³ªéæ¿¾æ¨¡çµ„ (Quality Filter)
# ==========================================
class KnowledgeFilter:
    def __init__(self):
        self.breakthrough_signals = {
            "efficiency": [r"linear complexity", r"O\(n\)", r"scaling law", r"memory-efficient"],
            "architecture": [r"novel architecture", r"parameter-efficient", r"state-space model", r"SSM"],
            "performance": [r"outperforms", r"state-of-the-art", r"SOTA", r"benchmarks"]
        }
        self.hype_signals = [r"revolutionary", r"surpasses human", r"the end of transformer"]

    def analyze(self, title, summary, threshold=0.2):
        text = f"{title} {summary}".lower()
        # è¨ˆç®—çªç ´å¾—åˆ†
        score = sum(0.3 for patterns in self.breakthrough_signals.values() for p in patterns if re.search(p, text))
        # æ‰£é™¤å™±é ­åˆ†
        score -= sum(0.5 for p in self.hype_signals if re.search(p, text))
        
        if score >= 0.6: label = "ã€æ ¸å¿ƒçªç ´ã€‘"
        elif score >= threshold: label = "ã€æŠ€è¡“å¢é‡ã€‘"
        else: label = "ã€ä¸€èˆ¬è³‡è¨Šã€‘"
        return {"label": label, "score": round(score, 2)}

# ==========================================
# 2. è¨˜æ†¶ç®¡ç†æ¨¡çµ„ (Memory Manager)
# ==========================================
class MemoryManager:
    def __init__(self, base_dir="LongTerm_Memory"):
        self.base_dir = base_dir
        if not os.path.exists(base_dir): os.makedirs(base_dir)

    def save(self, entry):
        category = entry['tags'][0] if entry['tags'] else "General"
        file_path = os.path.join(self.base_dir, f"{category}.md")
        is_new = not os.path.exists(file_path)
        with open(file_path, "a", encoding="utf-8") as f:
            if is_new: f.write(f"# {category} æŠ€è¡“å­˜æª”\n\n")
            f.write(f"### {entry['title']}\n")
            f.write(f"- **å“è³ª**: {entry['quality']['label']} ({entry['quality']['score']})\n")
            f.write(f"- **æ—¥æœŸ**: {entry['date']}\n")
            f.write(f"- **æ‘˜è¦**: {entry['summary']}\n")
            f.write(f"- **é€£çµ**: {entry['url']}\n\n---\n")

# ==========================================
# 3. æ ¸å¿ƒè‡ªå‹•åŒ–å¼•æ“ (AFKAES Engine)
# ==========================================
class AFKAES:
    def __init__(self):
        self.kf = KnowledgeFilter()
        self.mm = MemoryManager()
        self.keywords = ["Mamba", "SSM", "MoE", "Mixture of Experts", "RAG", "Long Context"]

    def run(self, depth=1):
        print(f"ğŸ“¡ [ç³»çµ±] å•Ÿå‹• 2026 å‰æ²¿æƒæ (æ·±åº¦åƒæ•¸: {depth})...")
        
        # éšæ®µ 1: é«˜ç²¾åº¦é—œéµå­—æœå°‹
        query = " OR ".join([f'all:"{k}"' for k in self.keywords])
        results = self._process_search(query, max_res=10*depth, threshold=0.2)

        # éšæ®µ 2: å›é€€æ©Ÿåˆ¶ (Fallback)
        if not results:
            print("âš ï¸ [è­¦å‘Š] é«˜è³ªé‡ç™¼ç¾ç‚º 0ï¼Œå•Ÿå‹•å›é€€æ©Ÿåˆ¶ï¼šæ”¾å¯¬æ¨™æº–ä¸¦æ“´å¤§æœå°‹...")
            results = self._process_search("cat:cs.AI OR cat:cs.CL", max_res=20*depth, threshold=0.1)

        if results:
            self._update_dashboard()
            print(f"âœ… [æˆåŠŸ] ä»Šæ—¥æ•ç² {len(results)} æ¢æœ‰åƒ¹å€¼æŠ€è¡“è³‡ç”¢ã€‚")
            return results
        else:
            print("âŒ [çµæŸ] ä»Šæ—¥ç„¡é¡¯è‘—æŠ€è¡“æ›´æ–°ã€‚")
            return []

    def _process_search(self, query, max_res, threshold):
        search = arxiv.Search(query=query, max_results=max_res, sort_by=arxiv.SortCriterion.SubmittedDate)
        found = []
        for r in search.results():
            q_report = self.kf.analyze(r.title, r.summary, threshold=threshold)
            if q_report['score'] >= threshold:
                data = {
                    "title": r.title, "summary": r.summary[:300] + "...",
                    "quality": q_report, "tags": ["AI_Research"], 
                    "url": r.entry_id, "date": str(r.published.date())
                }
                self.mm.save(data)
                found.append(data)
        return found

    def _update_dashboard(self):
        # ç”Ÿæˆç°¡å–®çš„å„€è¡¨æ¿ç´¢å¼•
        files = glob.glob("LongTerm_Memory/*.md")
        html = f"<html><head><meta charset='UTF-8'><style>body{{font-family:sans-serif;background:#0f172a;color:white;padding:40px;}} .card{{background:#1e293b;padding:15px;margin:10px;border-radius:8px;border:1px solid #334155;}}</style></head><body>"
        html += "<h1>ğŸš€ AFKAES 2026 å‰æ²¿æŠ€è¡“å„€è¡¨æ¿</h1>"
        html += f"<p>æœ€å¾ŒåŒæ­¥æ™‚é–“: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}</p>"
        for f in files:
            html += f"<div class='card'>ğŸ“ é¡åˆ¥æª”: <b>{os.path.basename(f)}</b></div>"
        html += "</body></html>"
        with open("Frontier_Dashboard.html", "w", encoding="utf-8") as f: f.write(html)

# ==========================================
# åŸ·è¡Œèˆ‡è¼¸å‡º
# ==========================================
if __name__ == "__main__":
    # æ”¯æ´å‘½ä»¤è¡Œï¼špython afkaes_core.py 1
    depth_param = int(sys.argv[1]) if len(sys.argv) > 1 else 1
    
    engine = AFKAES()
    discoveries = engine.run(depth=depth_param)

    if discoveries:
        best = max(discoveries, key=lambda x: x['quality']['score'])
        print("\n" + "="*40)
        print("ğŸ§  ä»Šæ—¥æœ€å€¼å¾—æ›è¼‰çµ¦ AI çš„æŠ€è¡“ï¼š")
        print(f"æ¨™é¡Œ: {best['title']}")
        print(f"åˆ†å€¼: {best['quality']['score']} | æ¨™ç±¤: {best['quality']['label']}")
        print(f"å»ºè­°: è«‹ Gemini åˆ†æè©²æŠ€è¡“å°ç¾æœ‰ Transformer æ¶æ§‹çš„å½±éŸ¿ã€‚")
        print("="*40)